{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d974e0-b1f4-4bc5-804e-416f2a3e60e9",
   "metadata": {},
   "source": [
    "# PixelCNN\n",
    "\n",
    "As explained at the end of the Na√Øve Face Generation notebook, to effectively generate images we need to sample each pixels given te surrounding one. This notebook presents an early approach to construct a model able to do that called **PixelCNN**. \n",
    "\n",
    "To formalize mathematically the problem, $p(x)$ represent the pixels distribution of an images. Which is equivalent to the joint probability of each pixels $p(x_1, x_2, ..., x_n)$. Modelizing the whole joint probability is too expensive, thus we made the hypothesis that $p(x_i) = p(x_i | x_{i-1})p(x_{i-1})$. Meaning that te probability of the pixel $x_i$ only depends on the previous pixel.\n",
    "\n",
    "This simplification makes it easier to compute the whole probability of an images that could be rewritte like that given our assumption :\n",
    "$p(x_n | x_{n-1})...p(x_2 | x_1)p(x_1)$\n",
    "\n",
    "PixelCNN will learn the parameter of those distribution based on example. In this notebook we are going to generate numbers from the **mnist** dataset. First part of the code will focus on the loading and pre-processing of the dataset.\n",
    "\n",
    "The dataset chose is the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. It consists of 28x28 images of handwritten digits. We preprocess the image to make them binary. Meaning that the background of the image have a value of 0 and the foreground of the image have a value of 1 without gray scale. This preprocessing will help the model to generate better numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dec488-b374-43fd-9534-452df48f33f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2448x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.mnist import *\n",
    "\n",
    "mnist_path = \"./ressources/mnist\"\n",
    "\n",
    "X, y = load_mnist(mnist_path, binary_images=True)\n",
    "\n",
    "plot_images(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f45f5",
   "metadata": {},
   "source": [
    "## Pixel CNN\n",
    "\n",
    "Our first Generator Network leverage the successful Convolutional Neural Network architecture. However, classic CNN are able to look at a pixel and all the surrounding pixels. As we are trying to generate the next pixel based on the previous one, the Convolutionnal Layer should be constrained to only look at the previous pixel. \n",
    "\n",
    "The next cell shows the implementation of such a CNN layer."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python (3.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
